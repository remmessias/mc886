{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 3 - Resolvendo Pac-Man com Algoritmos Evolucionários e Métodos e Aprendizado por Reforço\n",
    "\n",
    "Aluno: André Soranzzo Mota RA: 166404\n",
    "\n",
    "Aluna: Rebecca Moreira Messias RA: 186416\n",
    "\n",
    "*Participação*: O trabalho foi feito em Pair Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layout:  mediumClassic\n",
      "Pacman emerges victorious! Score: 1240\n",
      "Average Score: 1240.0\n",
      "Scores:        1240.0\n",
      "Win Rate:      1/1 (1.00)\n",
      "Record:        Win\n"
     ]
    }
   ],
   "source": [
    "!python pacman.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Modelo Evolucionário\n",
    "\n",
    "Nesta parte do projeto, será aplicado um modelo evolucionário para resolver o problema Pac-man. Para atingir este objetivo, deve-se encontrar uma solução adequada ao problema, avaliando-a de acordo com diferentes parâmetros.\n",
    "\n",
    "O modelo evolucionário adotado será o **Algoritmo Genético**. Os parâmetros utilizados neste problema são os seguintes: geração, tipo do labirinto, tamanho da população, vetor de populações.\n",
    "\n",
    "Define\n",
    "• The evolutionary model adopted\n",
    "• Variations on parameters\n",
    "• Fitness function adopted\n",
    "• Population size\n",
    "• Stop criteria\n",
    "• Selection technique\n",
    "• Crossover technique\n",
    "• Mutation technique\n",
    "• Replacement method\n",
    "• Mutation rate\n",
    "• Crossover rate\n",
    "\n",
    "O método será treinado para os 3 layouts (smallClassic, mediumClassic, e originalClassic), computando a função de avaliação (melhor, pior e médio score individual), o número de ações e o score por geração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Aprendizado por Reforço\n",
    "\n",
    "Nesta parte do trabalho, o jogo Pac-Man será solucionado através da implementação de um algoritmo RL (Reinforcement Learning).\n",
    "\n",
    "Define\n",
    "• The MDP formulation (states, actions, reward function)\n",
    "• The discretization model adopted\n",
    "• The number of training episodes\n",
    "• The stop criteria\n",
    "• The learning rate value and other parameter values used\n",
    "\n",
    "O método será treinado para os 3 layouts mencionados anteriormente, computando-se o reward, o número de ações e o score por episódio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Discussão dos Resultados e Comparação de Algoritmos\n",
    "\n",
    "Para cada layout o modelo será executado 10 vezes, tanto no EA (Evolutionary Algorithmn) quanto no RL (Reinforcement Learning), assumindo que os fantasmas aparecem em localizações distintas todas as vezes. Após computados os scores, será realizada a discussão e comparação dos resultados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
